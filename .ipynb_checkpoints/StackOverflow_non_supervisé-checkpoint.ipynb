{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fd38c5a-d383-4841-a703-ba7a9708bdd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.output_scroll { height: auto !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>link</th>\n",
       "      <th>view_count</th>\n",
       "      <th>score</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>word_count_title</th>\n",
       "      <th>word_count_clean_title</th>\n",
       "      <th>word_count_body</th>\n",
       "      <th>word_count_clean_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Manifest v3 background scripts/service worker ...</td>\n",
       "      <td>&lt;p&gt;I'm trying to migrate my browser extension ...</td>\n",
       "      <td>https://stackoverflow.com/questions/75043889/m...</td>\n",
       "      <td>17070</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>['google-chrome', 'firefox', 'cross-browser', ...</td>\n",
       "      <td>2023-01-07 21:27:38</td>\n",
       "      <td>manifest v background script service worker fi...</td>\n",
       "      <td>trying migrate browser extension expect work c...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>493</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Settings Menu missing Ubuntu 22.04</td>\n",
       "      <td>&lt;p&gt;So I was trying to get back the menu settin...</td>\n",
       "      <td>https://stackoverflow.com/questions/74985183/s...</td>\n",
       "      <td>42944</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>['ubuntu', 'menu', 'settings', 'new-operator',...</td>\n",
       "      <td>2023-01-02 17:06:35</td>\n",
       "      <td>setting menu missing ubuntu</td>\n",
       "      <td>trying get back menu setting dissapear ubutu m...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>166</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Does &amp;#39;use client&amp;#39; in Next.js 13 root l...</td>\n",
       "      <td>&lt;p&gt;I was trying Nextjs 13 with Next-auth and A...</td>\n",
       "      <td>https://stackoverflow.com/questions/74992326/d...</td>\n",
       "      <td>32460</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>['javascript', 'reactjs', 'next.js', 'server-s...</td>\n",
       "      <td>2023-01-03 10:49:12</td>\n",
       "      <td>use client next j root layout make whole route...</td>\n",
       "      <td>trying nextjs next auth apollo client wrap roo...</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>86</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>How can I stop Clang from overexpanding nested...</td>\n",
       "      <td>&lt;p&gt;Consider this code:&lt;/p&gt;\\r\\n&lt;pre&gt;&lt;code&gt;#incl...</td>\n",
       "      <td>https://stackoverflow.com/questions/74979866/h...</td>\n",
       "      <td>1385</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>['c++', 'clang', 'compiler-optimization', 'tem...</td>\n",
       "      <td>2023-01-02 07:28:00</td>\n",
       "      <td>stop clang overexpanding nested loop via template</td>\n",
       "      <td>consider code include iostream typedef long xi...</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>124</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Why dialog tag does not spread to the whole sc...</td>\n",
       "      <td>&lt;p&gt;In the middle of writing my project code I ...</td>\n",
       "      <td>https://stackoverflow.com/questions/75024007/w...</td>\n",
       "      <td>7395</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>['html', 'css', 'dialog', 'height', 'width']</td>\n",
       "      <td>2023-01-05 20:28:25</td>\n",
       "      <td>dialog tag spread whole screen even though set...</td>\n",
       "      <td>middle writing project code decided change pop...</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>1399</td>\n",
       "      <td>2418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  Manifest v3 background scripts/service worker ...   \n",
       "1           1                 Settings Menu missing Ubuntu 22.04   \n",
       "2           2  Does &#39;use client&#39; in Next.js 13 root l...   \n",
       "3           3  How can I stop Clang from overexpanding nested...   \n",
       "4           4  Why dialog tag does not spread to the whole sc...   \n",
       "\n",
       "                                                body  \\\n",
       "0  <p>I'm trying to migrate my browser extension ...   \n",
       "1  <p>So I was trying to get back the menu settin...   \n",
       "2  <p>I was trying Nextjs 13 with Next-auth and A...   \n",
       "3  <p>Consider this code:</p>\\r\\n<pre><code>#incl...   \n",
       "4  <p>In the middle of writing my project code I ...   \n",
       "\n",
       "                                                link  view_count  score  \\\n",
       "0  https://stackoverflow.com/questions/75043889/m...       17070     48   \n",
       "1  https://stackoverflow.com/questions/74985183/s...       42944     33   \n",
       "2  https://stackoverflow.com/questions/74992326/d...       32460     27   \n",
       "3  https://stackoverflow.com/questions/74979866/h...        1385     21   \n",
       "4  https://stackoverflow.com/questions/75024007/w...        7395     20   \n",
       "\n",
       "   answer_count                                               tags  \\\n",
       "0             3  ['google-chrome', 'firefox', 'cross-browser', ...   \n",
       "1             4  ['ubuntu', 'menu', 'settings', 'new-operator',...   \n",
       "2             2  ['javascript', 'reactjs', 'next.js', 'server-s...   \n",
       "3             3  ['c++', 'clang', 'compiler-optimization', 'tem...   \n",
       "4             1       ['html', 'css', 'dialog', 'height', 'width']   \n",
       "\n",
       "         creation_date                                        clean_title  \\\n",
       "0  2023-01-07 21:27:38  manifest v background script service worker fi...   \n",
       "1  2023-01-02 17:06:35                        setting menu missing ubuntu   \n",
       "2  2023-01-03 10:49:12  use client next j root layout make whole route...   \n",
       "3  2023-01-02 07:28:00  stop clang overexpanding nested loop via template   \n",
       "4  2023-01-05 20:28:25  dialog tag spread whole screen even though set...   \n",
       "\n",
       "                                          clean_body  word_count_title  \\\n",
       "0  trying migrate browser extension expect work c...                 7   \n",
       "1  trying get back menu setting dissapear ubutu m...                 5   \n",
       "2  trying nextjs next auth apollo client wrap roo...                13   \n",
       "3  consider code include iostream typedef long xi...                11   \n",
       "4  middle writing project code decided change pop...                19   \n",
       "\n",
       "   word_count_clean_title  word_count_body  word_count_clean_body  \n",
       "0                       7              493                    263  \n",
       "1                       4              166                    150  \n",
       "2                      11               86                     41  \n",
       "3                       7              124                     70  \n",
       "4                      10             1399                   2418  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#tracking mlflow\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "import mlflow.sklearn\n",
    "from time import time\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,hamming_loss, jaccard_score, confusion_matrix, roc_curve, auc)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "#Extraction de features\n",
    "#Bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "\n",
    "#sauvegarde les modeles\n",
    "import joblib\n",
    "\n",
    "#pour slugifier une string\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "#analyse des topics\n",
    "import pyLDAvis\n",
    "\n",
    "#empecher les messages d'erreur\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.disable(logging.WARNING) # disable WARNING, INFO and DEBUG logging everywhere\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Formatage taille cellule pour s'adapter aux graphiques\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.output_scroll { height: auto !important; }</style>\"))\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./filtered_questions_clean.csv\",sep=',', encoding='utf-8')  \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4006442-5cb4-4c52-8824-b9b70a6962aa",
   "metadata": {},
   "source": [
    "## Fonction pour slugifier une string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efae1105-e8eb-4218-882d-bdf080a7ed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slugify(value):\n",
    "    # Normaliser la chaîne pour enlever les accents\n",
    "    value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n",
    "    \n",
    "    # Remplacer les caractères non-alphanumériques par des tirets\n",
    "    value = re.sub(r'[^a-zA-Z0-9]+', '-', value)\n",
    "    \n",
    "    # Enlever les tirets en début et fin de chaîne\n",
    "    value = value.strip('-')\n",
    "    \n",
    "    # Convertir en minuscules\n",
    "    return value.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504a6c5d-8158-4635-929c-284e9e95033c",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a9cebb4-ae64-4f94-9405-e10ee8c4c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binariser les tags\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_tags = mlb.fit_transform(df['tags'])\n",
    "\n",
    "# Séparer les données en jeux d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['clean_title', 'clean_body']], df_tags, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d9fb84-f714-49d4-a1a3-fe184c17990a",
   "metadata": {},
   "source": [
    "## Extraction de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89deea98-3005-4113-a34a-1a8238455249",
   "metadata": {},
   "source": [
    "### Définir les fonctions de vectorisation (Bag of words + LDA/NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c59d6fc-d953-4617-975d-3707070d4b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour vectorisation avec CountVectorizer + LDA sur \"Title\" + \"Body\"\n",
    "def vectorize_count_lda_title_body(X_train, n_components=10):\n",
    "    count_vect = CountVectorizer()\n",
    "    X_train_count = count_vect.fit_transform(X_train['clean_title'] + \" \" + X_train['clean_body'])\n",
    "    \n",
    "    lda = LatentDirichletAllocation(n_components=n_components, random_state=0)\n",
    "    X_train_lda = lda.fit_transform(X_train_count)\n",
    "    \n",
    "    return X_train_lda, lda, count_vect\n",
    "\n",
    "# Fonction pour vectorisation avec CountVectorizer + LDA\n",
    "def vectorize_count_lda_fit_title_transform_title_body(X_train, X_test=None, n_components=10):\n",
    "    count_vect = CountVectorizer()\n",
    "    # Fit sur le titre uniquement\n",
    "    count_vect.fit(X_train['clean_title'])\n",
    "    \n",
    "    # Transform sur la combinaison \"Title\" + \"Body\"\n",
    "    X_train_count = count_vect.transform(X_train['clean_title'] + \" \" + X_train['clean_body'])\n",
    "    \n",
    "    lda = LatentDirichletAllocation(n_components=n_components, random_state=0)\n",
    "    X_train_lda = lda.fit_transform(X_train_count)\n",
    "    \n",
    "    return X_train_lda, lda, count_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb695c4c-6f02-4153-95f0-7923e3d3af20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour vectorisation avec TfidfVectorizer + NMF sur \"Title\" + \"Body\"\n",
    "def vectorize_tfidf_nmf_title_body(X_train, n_components=10):\n",
    "    # Handle missing values\n",
    "    X_train = X_train.fillna(\"\")\n",
    "    \n",
    "    tfidf_vect = TfidfVectorizer()\n",
    "    X_train_tfidf = tfidf_vect.fit_transform(X_train['clean_title'] + \" \" + X_train['clean_body'])\n",
    "\n",
    "    nmf = NMF(n_components=n_components, random_state=0)\n",
    "    X_train_nmf = nmf.fit_transform(X_train_tfidf)\n",
    "    \n",
    "    return X_train_nmf, nmf, tfidf_vect\n",
    "\n",
    "# Fonction pour vectorisation avec TfidfVectorizer + NMF\n",
    "def vectorize_tfidf_nmf_fit_title_transform_title_body(X_train, X_test=None, n_components=10):\n",
    "    # Handle missing values\n",
    "    X_train = X_train.fillna(\"\")\n",
    "    \n",
    "    tfidf_vect = TfidfVectorizer()\n",
    "    # Fit sur le titre uniquement\n",
    "    tfidf_vect.fit(X_train['clean_title'])\n",
    "    \n",
    "    # Transform sur la combinaison \"Title\" + \"Body\"\n",
    "    X_train_tfidf = tfidf_vect.transform(X_train['clean_title'] + \" \" + X_train['clean_body'])\n",
    "    \n",
    "    nmf = NMF(n_components=n_components, random_state=0)\n",
    "    X_train_nmf = nmf.fit_transform(X_train_tfidf)\n",
    "    \n",
    "    return X_train_nmf, nmf, tfidf_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0165add-91c0-4bbd-8108-7d02c1028776",
   "metadata": {},
   "source": [
    " ## Fonction pour Cacluler le taux de couverture des mots des questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "449f5725-693b-46f5-b48e-9d45f9879fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer le taux de couverture des mots\n",
    "def calculate_word_coverage(X_test, vectorizer):\n",
    "    \"\"\"\n",
    "    Calcule le taux de couverture des mots dans le jeu de test par rapport au vocabulaire du vectorizer.\n",
    "    \n",
    "    Parameters:\n",
    "        X_test: Jeu de test (DataFrame avec des colonnes 'clean_title' et 'clean_body')\n",
    "        vectorizer: Vectoriseur déjà entraîné sur le jeu d'entraînement\n",
    "    \n",
    "    Returns:\n",
    "        coverage_rate: Le pourcentage de mots du jeu de test couverts par le vocabulaire du vectorizer\n",
    "    \"\"\"\n",
    "    # Remplir les valeurs manquantes avec des chaînes vides\n",
    "    X_test = X_test.fillna(\"\")\n",
    "    \n",
    "    # Nombre total de mots uniques dans le vocabulaire (déjà appris lors du fit sur X_train)\n",
    "    total_vocab = len(vectorizer.get_feature_names_out())\n",
    "    \n",
    "    # Transformer les questions de test pour obtenir les mots utilisés dans X_test\n",
    "    X_test_transformed = vectorizer.transform(X_test['clean_title'] + \" \" + X_test['clean_body'])\n",
    "    \n",
    "    # Compter le nombre de mots uniques utilisés dans le jeu de test\n",
    "    word_usage = (X_test_transformed > 0).sum(axis=0)\n",
    "    covered_words = (word_usage > 0).sum()\n",
    "    \n",
    "    # Calculer le taux de couverture par rapport au vocabulaire total\n",
    "    coverage_rate = covered_words / total_vocab\n",
    "    return coverage_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd08a94-68df-4f07-be0a-1491dacd7905",
   "metadata": {},
   "source": [
    "## Fonction pour enregistrer les informations dans mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "264e54db-dbf2-4f00-8393-158921076ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_experiment_to_mlflow(model, vectorizer, X_train, X_test, params, method_name, train_quest_words_csv_path, test_quest_words_csv_path):\n",
    "    # Initialiser le client MLflow\n",
    "    client = MlflowClient()\n",
    "    \n",
    "    # Calculer le taux de couverture des mots sur le jeu de test\n",
    "    word_coverage = calculate_word_coverage(X_test, vectorizer)  # Utiliser X_test\n",
    "    \n",
    "    # Démarrer un enregistrement MLflow avec un nom personnalisé pour le run\n",
    "    with mlflow.start_run(run_name=method_name) as run:\n",
    "        # Enregistrer les paramètres, y compris n_components\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_param(\"n_components\", model.n_components if hasattr(model, 'n_components') else \"N/A\")\n",
    "        \n",
    "        # Loguer les sujets ou thèmes extraits\n",
    "        for idx, topic in enumerate(model.components_):\n",
    "            topic_words = [vectorizer.get_feature_names_out()[i] for i in topic.argsort()[:-10 - 1:-1]]\n",
    "            mlflow.log_text(\"\\n\".join(topic_words), f\"topic_{idx}_{method_name}.txt\")\n",
    "        \n",
    "        # Loguer le modèle LDA ou NMF en tant qu'artifact\n",
    "        model_uri = f\"runs:/{run.info.run_id}/{method_name}_model\"\n",
    "        mlflow.sklearn.log_model(model, f\"{method_name}_model\")\n",
    "\n",
    "        # Enregistrer le modèle dans le registre des modèles\n",
    "        registered_model_name = f\"{method_name}_registered_model\"\n",
    "        mlflow.register_model(model_uri=model_uri, name=registered_model_name)\n",
    "\n",
    "        # Vérifier si le modèle est une instance de LatentDirichletAllocation\n",
    "        if isinstance(model, LatentDirichletAllocation):\n",
    "            # Créer la visualisation pyLDAvis\n",
    "            X_train_transformed = vectorizer.transform(X_train['clean_title'] + \" \" + X_train['clean_body'])\n",
    "            panel = pyLDAvis.prepare(\n",
    "                topic_term_dists=model.components_,\n",
    "                doc_topic_dists=model.transform(X_train_transformed),\n",
    "                doc_lengths=X_train_transformed.sum(axis=1).A1,\n",
    "                vocab=vectorizer.get_feature_names_out(),\n",
    "                term_frequency=X_train_transformed.sum(axis=0).A1\n",
    "            )\n",
    "            \n",
    "            # Sauvegarder la visualisation en tant que fichier HTML\n",
    "            vis_html_path = f\"{method_name}_lda_visualization.html\"\n",
    "            pyLDAvis.save_html(panel, vis_html_path)\n",
    "            \n",
    "            # Loguer le fichier HTML comme artefact dans MLflow\n",
    "            mlflow.log_artifact(vis_html_path)\n",
    "\n",
    "        try:\n",
    "            # Loguer les artefacts\n",
    "            client.log_artifact(run.info.run_id, train_quest_words_csv_path)\n",
    "            client.log_artifact(run.info.run_id, test_quest_words_csv_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de l'enregistrement des artefacts : {e}\")\n",
    "            print(\"Les fichiers ont été enregistrés localement. Téléchargez-les manuellement via l'interface MLflow.\")\n",
    "        \n",
    "        # Enregistrer le taux de couverture des mots dans MLflow\n",
    "        mlflow.log_metric(\"word_coverage\", word_coverage)  # Loguer la couverture sur le jeu de test\n",
    "        \n",
    "        print(f\"Taux de couverture des mots : {word_coverage:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07314a92-ba65-460b-9283-e214d21eaaef",
   "metadata": {},
   "source": [
    "### Définir la fonction pour exécuter l'expérience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc278e51-4053-47e2-b01c-49bb417bcc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_unsupervised_experiment(vectorization_method, X_train, X_test, params, method_name):\n",
    "    X_train = X_train.fillna(\"\")\n",
    "    X_test = X_test.fillna(\"\")\n",
    "    \n",
    "    # Vectoriser X_train en utilisant la méthode de vectorisation fournie\n",
    "    X_train_vect, model, vectorizer = vectorization_method(X_train, n_components=params['n_components'])\n",
    "    params['vectorization'] = method_name\n",
    "\n",
    "    # Créer la matrice Mtopics-words\n",
    "    Mtopics_words = model.components_\n",
    "\n",
    "    # Transformer les données d'entraînement avec le même vectoriseur que celui utilisé pour l'entraînement\n",
    "    X_train_transformed = vectorizer.transform(X_train['clean_title'] + \" \" + X_train['clean_body'])\n",
    "    M_train_quest_topics = model.transform(X_train_transformed)\n",
    "\n",
    "    # Calculer la matrice M(train)quest-words\n",
    "    M_train_quest_words = np.dot(M_train_quest_topics, Mtopics_words)\n",
    "\n",
    "    # Convertir la matrice M(train)quest-words en DataFrame\n",
    "    df_Mtrain_quest_words = pd.DataFrame(M_train_quest_words, columns=vectorizer.get_feature_names_out())\n",
    "    \n",
    "    # Sauvegarder la matrice M(train)quest-words en tant que fichier CSV\n",
    "    train_quest_words_csv_path = f\"Mtrain_quest_words_{method_name}.csv\"\n",
    "    df_Mtrain_quest_words.to_csv(train_quest_words_csv_path, index=False)\n",
    "    \n",
    "    # Transformer les données de test avec le même vectoriseur\n",
    "    X_test_transformed = vectorizer.transform(X_test['clean_title'] + \" \" + X_test['clean_body'])\n",
    "    M_test_quest_topics = model.transform(X_test_transformed)\n",
    "\n",
    "    # Calculer la matrice M(test)quest-words\n",
    "    M_test_quest_words = np.dot(M_test_quest_topics, Mtopics_words)\n",
    "\n",
    "    # Convertir la matrice M(test)quest-words en DataFrame\n",
    "    df_Mtest_quest_words = pd.DataFrame(M_test_quest_words, columns=vectorizer.get_feature_names_out())\n",
    "    \n",
    "    # Sauvegarder la matrice M(test)quest-words en tant que fichier CSV\n",
    "    test_quest_words_csv_path = f\"Mtest_quest_words_{method_name}.csv\"\n",
    "    df_Mtest_quest_words.to_csv(test_quest_words_csv_path, index=False)\n",
    "    \n",
    "    # Sauvegarder le modèle et le vectoriseur\n",
    "    model_name = slugify(method_name)\n",
    "    joblib.dump(model, model_name + \"_model.pkl\")\n",
    "    joblib.dump(vectorizer, model_name + \"_vectorizer.pkl\")\n",
    "    \n",
    "    # Appeler la fonction pour enregistrer les résultats dans MLflow, passer X_test pour calculer la couverture des mots\n",
    "    log_experiment_to_mlflow(model, vectorizer, X_train, X_test, params, method_name, train_quest_words_csv_path, test_quest_words_csv_path)\n",
    "\n",
    "    # Afficher les thèmes\n",
    "    print(f\"\\n\\033[1m{method_name} Topics/Themes:\\033[0m\")\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(f\"\\nTopic/Theme {idx}:\")\n",
    "        print([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[:-10 - 1:-1]])\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae458d53-cd14-4a92-911f-4723570e9dd7",
   "metadata": {},
   "source": [
    "## echantilloner pour réduire les ressources necessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d71a12b-0d0c-43d9-b56d-d83723752f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.sample(frac=0.1, random_state=42)  # Utilisez seulement 10% des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a20e5a1-ed6a-41fa-80dc-41a95e70ce71",
   "metadata": {},
   "source": [
    "### Executer les 2 experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92542cd5-040d-4f71-a827-d32b2b207a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'CountVectorizer + LDA fit on Title and Body_registered_model'.\n",
      "Created version '1' of model 'CountVectorizer + LDA fit on Title and Body_registered_model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur lors de l'enregistrement des artefacts : API request to http://127.0.0.1:5000/api/2.0/mlflow-artifacts/artifacts/0/4747cae7a73d4581b9f463bbef6a3995/artifacts/Mtrain_quest_words_CountVectorizer + LDA fit on Title and Body.csv failed with exception HTTPConnectionPool(host='127.0.0.1', port=5000): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/0/4747cae7a73d4581b9f463bbef6a3995/artifacts/Mtrain_quest_words_CountVectorizer%20+%20LDA%20fit%20on%20Title%20and%20Body.csv (Caused by ProtocolError('Connection aborted.', ConnectionResetError(10054, 'Une connexion existante a dû être fermée par l’hôte distant', None, 10054, None)))\n",
      "Les fichiers ont été enregistrés localement. Téléchargez-les manuellement via l'interface MLflow.\n",
      "Taux de couverture des mots : 0.48\n",
      "\n",
      "\n",
      "\u001b[1mCountVectorizer + LDA fit on Title and Body Topics/Themes:\u001b[0m\n",
      "\n",
      "Topic/Theme 0:\n",
      "['data', 'class', 'value', 'type', 'form', 'id', 'name', 'const', 'user', 'string']\n",
      "\n",
      "Topic/Theme 1:\n",
      "['div', 'color', 'text', 'class', 'px', 'image', 'const', 'width', 'style', 'self']\n",
      "\n",
      "Topic/Theme 2:\n",
      "['file', 'app', 'error', 'user', 'http', 'module', 'server', 'project', 'package', 'python']\n",
      "\n",
      "Topic/Theme 3:\n",
      "['id', 'name', 'string', 'public', 'model', 'return', 'class', 'value', 'data', 'true']\n",
      "\n",
      "Topic/Theme 4:\n",
      "['model', 'data', 'string', 'error', 'return', 'user', 'code', 'input', 'train', 'value']\n",
      "\n",
      "Topic/Theme 5:\n",
      "['android', 'layout', 'id', 'app', 'com', 'self', 'view', 'import', 'new', 'react']\n",
      "\n",
      "Topic/Theme 6:\n",
      "['date', 'data', 'file', 'df', 'const', 'id', 'get', 'error', 'like', 'code']\n",
      "\n",
      "Topic/Theme 7:\n",
      "['int', 'thread', 'using', 'connection', 'error', 'include', 'code', 'task', 'use', 'main']\n",
      "\n",
      "Topic/Theme 8:\n",
      "['div', 'driver', 'value', 'page', 'element', 'key', 'code', 'return', 'node', 'var']\n",
      "\n",
      "Topic/Theme 9:\n",
      "['java', 'org', 'springframework', 'spring', 'version', 'artifactid', 'dependency', 'groupid', 'jar', 'boot']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'CountVectorizer + LDA fit on Title and transform on Title + Body_registered_model'.\n",
      "Created version '1' of model 'CountVectorizer + LDA fit on Title and transform on Title + Body_registered_model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux de couverture des mots : 0.87\n",
      "\n",
      "\n",
      "\u001b[1mCountVectorizer + LDA fit on Title and transform on Title + Body Topics/Themes:\u001b[0m\n",
      "\n",
      "Topic/Theme 0:\n",
      "['value', 'int', 'std', 'node', 'const', 'return', 'array', 'expo', 'list', 'char']\n",
      "\n",
      "Topic/Theme 1:\n",
      "['div', 'class', 'button', 'id', 'page', 'html', 'text', 'style', 'script', 'li']\n",
      "\n",
      "Topic/Theme 2:\n",
      "['app', 'error', 'server', 'http', 'using', 'client', 'service', 'api', 'use', 'run']\n",
      "\n",
      "Topic/Theme 3:\n",
      "['user', 'model', 'name', 'form', 'image', 'class', 'import', 'request', 'data', 'post']\n",
      "\n",
      "Topic/Theme 4:\n",
      "['file', 'lib', 'package', 'python', 'line', 'error', 'py', 'module', 'project', 'build']\n",
      "\n",
      "Topic/Theme 5:\n",
      "['file', 'write', 'function', 'code', 'wait', 'operation', 'ctrl', 'stat', 'name', 'document']\n",
      "\n",
      "Topic/Theme 6:\n",
      "['string', 'id', 'data', 'public', 'return', 'new', 'get', 'type', 'value', 'null']\n",
      "\n",
      "Topic/Theme 7:\n",
      "['android', 'const', 'import', 'color', 'react', 'text', 'component', 'app', 'self', 'layout']\n",
      "\n",
      "Topic/Theme 8:\n",
      "['data', 'df', 'column', 'value', 'output', 'self', 'row', 'model', 'like', 'input']\n",
      "\n",
      "Topic/Theme 9:\n",
      "['java', 'org', 'com', 'springframework', 'version', 'spring', 'dependency', 'jar', 'import', 'core']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'TfidfVectorizer + NMF fit on Title and Body_registered_model'.\n",
      "Created version '1' of model 'TfidfVectorizer + NMF fit on Title and Body_registered_model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur lors de l'enregistrement des artefacts : API request to http://127.0.0.1:5000/api/2.0/mlflow-artifacts/artifacts/0/cdb492c199db4131903b715bd6eed3cb/artifacts/Mtrain_quest_words_TfidfVectorizer + NMF fit on Title and Body.csv failed with exception HTTPConnectionPool(host='127.0.0.1', port=5000): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/0/cdb492c199db4131903b715bd6eed3cb/artifacts/Mtrain_quest_words_TfidfVectorizer%20+%20NMF%20fit%20on%20Title%20and%20Body.csv (Caused by ProtocolError('Connection aborted.', ConnectionResetError(10054, 'Une connexion existante a dû être fermée par l’hôte distant', None, 10054, None)))\n",
      "Les fichiers ont été enregistrés localement. Téléchargez-les manuellement via l'interface MLflow.\n",
      "Taux de couverture des mots : 0.48\n",
      "\n",
      "\n",
      "\u001b[1mTfidfVectorizer + NMF fit on Title and Body Topics/Themes:\u001b[0m\n",
      "\n",
      "Topic/Theme 0:\n",
      "['string', 'public', 'int', 'array', 'list', 'char', 'value', 'return', 'class', 'std']\n",
      "\n",
      "Topic/Theme 1:\n",
      "['df', 'column', 'table', 'id', 'row', 'data', 'value', 'date', 'dataframe', 'col']\n",
      "\n",
      "Topic/Theme 2:\n",
      "['div', 'px', 'button', 'class', 'text', 'color', 'style', 'html', 'width', 'li']\n",
      "\n",
      "Topic/Theme 3:\n",
      "['org', 'java', 'artifactid', 'groupid', 'springframework', 'spring', 'dependency', 'boot', 'version', 'jar']\n",
      "\n",
      "Topic/Theme 4:\n",
      "['file', 'run', 'app', 'error', 'python', 'server', 'project', 'path', 'node', 'script']\n",
      "\n",
      "Topic/Theme 5:\n",
      "['model', 'self', 'import', 'train', 'py', 'def', 'class', 'layer', 'data', 'django']\n",
      "\n",
      "Topic/Theme 6:\n",
      "['android', 'layout', 'app', 'com', 'gradle', 'id', 'color', 'flutter', 'parent', 'view']\n",
      "\n",
      "Topic/Theme 7:\n",
      "['user', 'email', 'token', 'request', 'password', 'id', 'login', 'form', 'response', 'username']\n",
      "\n",
      "Topic/Theme 8:\n",
      "['const', 'react', 'import', 'console', 'component', 'app', 'log', 're', 'data', 'response']\n",
      "\n",
      "Topic/Theme 9:\n",
      "['image', 'img', 'cv', 'png', 'url', 'jpg', 'description', 'video', 'enter', 'path']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'TfidfVectorizer + NMF fit on Title and transform on Title + Body_registered_model'.\n",
      "Created version '1' of model 'TfidfVectorizer + NMF fit on Title and transform on Title + Body_registered_model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur lors de l'enregistrement des artefacts : API request to http://127.0.0.1:5000/api/2.0/mlflow-artifacts/artifacts/0/03f861eb24e0498285714775f2020507/artifacts/Mtest_quest_words_TfidfVectorizer + NMF fit on Title and transform on Title + Body.csv failed with exception HTTPConnectionPool(host='127.0.0.1', port=5000): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/0/03f861eb24e0498285714775f2020507/artifacts/Mtest_quest_words_TfidfVectorizer%20+%20NMF%20fit%20on%20Title%20and%20transform%20on%20Title%20+%20Body.csv (Caused by ProtocolError('Connection aborted.', ConnectionResetError(10054, 'Une connexion existante a dû être fermée par l’hôte distant', None, 10054, None)))\n",
      "Les fichiers ont été enregistrés localement. Téléchargez-les manuellement via l'interface MLflow.\n",
      "Taux de couverture des mots : 0.87\n",
      "\n",
      "\n",
      "\u001b[1mTfidfVectorizer + NMF fit on Title and transform on Title + Body Topics/Themes:\u001b[0m\n",
      "\n",
      "Topic/Theme 0:\n",
      "['file', 'app', 'http', 'tried', 'user', 'error', 'com', 'run', 'code', 'work']\n",
      "\n",
      "Topic/Theme 1:\n",
      "['const', 'import', 'console', 'return', 'log', 'await', 'export', 'react', 'data', 'async']\n",
      "\n",
      "Topic/Theme 2:\n",
      "['int', 'string', 'char', 'return', 'std', 'code', 'array', 'include', 'void', 'print']\n",
      "\n",
      "Topic/Theme 3:\n",
      "['public', 'class', 'string', 'private', 'new', 'return', 'void', 'set', 'get', 'method']\n",
      "\n",
      "Topic/Theme 4:\n",
      "['div', 'class', 'button', 'text', 'width', 'style', 'color', 'span', 'height', 'classname']\n",
      "\n",
      "Topic/Theme 5:\n",
      "['id', 'name', 'user', 'select', 'table', 'query', 'type', 'null', 'true', 'date']\n",
      "\n",
      "Topic/Theme 6:\n",
      "['org', 'java', 'springframework', 'version', 'dependency', 'import', 'com', 'jar', 'spring', 'boot']\n",
      "\n",
      "Topic/Theme 7:\n",
      "['self', 'model', 'import', 'true', 'def', 'name', 'py', 'train', 'class', 'print']\n",
      "\n",
      "Topic/Theme 8:\n",
      "['var', 'new', 'let', 'await', 'function', 'document', 'task', 'context', 'result', 'builder']\n",
      "\n",
      "Topic/Theme 9:\n",
      "['df', 'data', 'like', 'column', 'value', 'row', 'want', 'would', 'date', 'table']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Définir les paramètres communs\n",
    "params = {\n",
    "    \"n_components\": 10\n",
    "}\n",
    "\n",
    "# Exécuter l'expérience pour CountVectorizer + LDA avec fit et transfom sur \"Title\" + \"Body\"\n",
    "run_unsupervised_experiment(\n",
    "    vectorization_method=vectorize_count_lda_title_body,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    params=params,\n",
    "    method_name=\"CountVectorizer + LDA fit on Title and Body\"\n",
    ")\n",
    "\n",
    "\n",
    "# Exécuter l'expérience pour CountVectorizer + LDA avec fit sur \"Title\" et transform sur \"Title\" + \"Body\"\n",
    "run_unsupervised_experiment(\n",
    "    vectorization_method=vectorize_count_lda_fit_title_transform_title_body,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    params=params,\n",
    "    method_name=\"CountVectorizer + LDA fit on Title and transform on Title + Body\"\n",
    ")\n",
    "\n",
    "# Exécuter l'expérience pour TfidfVectorizer + NMF avec fit et transfom sur \"Title\" + \"Body\"\n",
    "run_unsupervised_experiment(\n",
    "    vectorization_method=vectorize_tfidf_nmf_title_body,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    params=params,\n",
    "    method_name=\"TfidfVectorizer + NMF fit on Title and Body\"\n",
    ")\n",
    "\n",
    "# Exécuter l'expérience pour TfidfVectorizer + NMF avec fit sur \"Title\" et transform sur \"Title\" + \"Body\"\n",
    "run_unsupervised_experiment(\n",
    "    vectorization_method=vectorize_tfidf_nmf_fit_title_transform_title_body,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    params=params,\n",
    "    method_name=\"TfidfVectorizer + NMF fit on Title and transform on Title + Body\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c78e49a8-faef-4148-b2a5-6d17373975cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_vectorizer(model_path, vectorizer_path):\n",
    "    \"\"\"\n",
    "    Charge le modèle et le vectoriseur sauvegardés avec joblib.\n",
    "    \n",
    "    Parameters:\n",
    "        model_path (str): Chemin du fichier de modèle.\n",
    "        vectorizer_path (str): Chemin du fichier du vectoriseur.\n",
    "    \n",
    "    Returns:\n",
    "        model, vectorizer: Le modèle et le vectoriseur chargés.\n",
    "    \"\"\"\n",
    "    model = joblib.load(model_path)\n",
    "    vectorizer = joblib.load(vectorizer_path)\n",
    "    return model, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10779e38-50e4-4c77-9b72-96dc5c9a2ee9",
   "metadata": {},
   "source": [
    "## Test de visu pour LDA + Countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf20e7de-b558-4251-b7db-929764541609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_topic_for_question(question, model, vectorizer, n_words=10):\n",
    "    \"\"\"\n",
    "    Prédit les groupes de mots pour une question en utilisant un modèle LDA ou NMF.\n",
    "    \n",
    "    Parameters:\n",
    "        question (str): Question à prédire.\n",
    "        model: Modèle LDA ou NMF déjà entraîné.\n",
    "        vectorizer: Vectoriseur CountVectorizer ou TfidfVectorizer utilisé avec le modèle.\n",
    "        n_words (int): Nombre de mots pertinents à afficher pour chaque thème.\n",
    "    \n",
    "    Returns:\n",
    "        None. Affiche les thèmes prédits et leurs mots pertinents.\n",
    "    \"\"\"\n",
    "    # Vectoriser la question\n",
    "    question_vect = vectorizer.transform([question])\n",
    "    \n",
    "    # Obtenir les distributions de thèmes pour la question\n",
    "    topic_distribution = model.transform(question_vect)\n",
    "    \n",
    "    # Afficher les thèmes et leurs mots les plus pertinents\n",
    "    print(\"\\n\\033[1mPredicted Topics for the Question:\\033[0m\")\n",
    "    for idx, topic_prob in enumerate(topic_distribution[0]):\n",
    "        if topic_prob > 0.1:  # Seuil pour afficher les thèmes les plus pertinents\n",
    "            topic_words = [vectorizer.get_feature_names_out()[i] for i in model.components_[idx].argsort()[:-n_words - 1:-1]]\n",
    "            print(f\"Topic {idx} (probabilité: {topic_prob:.2f}):\\nMots: {', '.join(topic_words)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fd7bbce-db5c-444f-9e21-fb39ffe95b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation avec le modèle et le vectoriseur sauvegardés\n",
    "model_path = \"countvectorizer-lda-fit-on-title-and-transform-on-title-body_model.pkl\"  # Chemin vers votre modèle\n",
    "vectorizer_path = \"countvectorizer-lda-fit-on-title-and-transform-on-title-body_vectorizer.pkl\"  # Chemin vers votre vectoriseur\n",
    "model, vectorizer = load_model_and_vectorizer(model_path, vectorizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a87950db-3070-4959-8230-20d91b3acf5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mPredicted Topics for the Question:\u001b[0m\n",
      "Topic 2 (probabilité: 0.26):\n",
      "Mots: app, error, server, http, using, client, service, api, use, run\n",
      "\n",
      "Topic 4 (probabilité: 0.54):\n",
      "Mots: file, lib, package, python, line, error, py, module, project, build\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Utilisez une question en dur\n",
    "question = \"How to integrate my css file into my project ?\"\n",
    "predict_topic_for_question(question, model, vectorizer, n_words=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878b97e9-0c59-449c-aee6-a7a30444800b",
   "metadata": {},
   "source": [
    "## Test de visu pour NMF + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ed40df3-9214-4b53-b4ec-f670aa3722c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_topic_for_question_nmf(question, model, vectorizer, n_words=10):\n",
    "    question_vect = vectorizer.transform([question])\n",
    "    topic_distribution = model.transform(question_vect)\n",
    "\n",
    "    # Normaliser les poids pour les interpréter comme des probabilités (si nécessaire)\n",
    "    topic_distribution = topic_distribution / topic_distribution.sum()\n",
    "    \n",
    "    print(\"\\n\\033[1mPredicted Topics for the Question:\\033[0m\")\n",
    "    for idx, topic_prob in enumerate(topic_distribution[0]):\n",
    "        if topic_prob > 0.05:  # Abaisser le seuil\n",
    "            topic_words = [vectorizer.get_feature_names_out()[i] for i in model.components_[idx].argsort()[:-n_words - 1:-1]]\n",
    "            print(f\"Topic {idx} (probabilité: {topic_prob:.2f}):\\nMots: {', '.join(topic_words)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20822f24-6506-4f7a-8db9-f84942e065b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation avec le modèle et le vectoriseur sauvegardés\n",
    "model_path = \"tfidfvectorizer-nmf-fit-on-title-and-transform-on-title-body_model.pkl\"  # Chemin vers votre modèle\n",
    "vectorizer_path = \"tfidfvectorizer-nmf-fit-on-title-and-transform-on-title-body_vectorizer.pkl\"  # Chemin vers votre vectoriseur\n",
    "model, vectorizer = load_model_and_vectorizer(model_path, vectorizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "673c27e4-de52-4e42-9a0c-91ab70ca6814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mPredicted Topics for the Question:\u001b[0m\n",
      "Topic 0 (probabilité: 1.00):\n",
      "Mots: file, app, http, tried, user, error, com, run, code, work\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Utilisez une question en dur\n",
    "question = \"How to integrate my css file into my project ?\"\n",
    "predict_topic_for_question_nmf(question, model, vectorizer, n_words=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
