{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f71c885b-df81-4dba-9ace-7fdc7ddbb270",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] Le module spécifié est introuvable. Error loading \"C:\\Users\\MAUD\\anaconda3\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Bert\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     logging,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     52\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\__init__.py:34\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     add_code_sample_docstrings,\n\u001b[0;32m     28\u001b[0m     add_end_docstrings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     replace_return_docstrings,\n\u001b[0;32m     33\u001b[0m )\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     35\u001b[0m     ContextManagers,\n\u001b[0;32m     36\u001b[0m     ExplicitEnum,\n\u001b[0;32m     37\u001b[0m     ModelOutput,\n\u001b[0;32m     38\u001b[0m     PaddingStrategy,\n\u001b[0;32m     39\u001b[0m     TensorType,\n\u001b[0;32m     40\u001b[0m     add_model_info_to_auto_map,\n\u001b[0;32m     41\u001b[0m     add_model_info_to_custom_pipelines,\n\u001b[0;32m     42\u001b[0m     cached_property,\n\u001b[0;32m     43\u001b[0m     can_return_loss,\n\u001b[0;32m     44\u001b[0m     expand_dims,\n\u001b[0;32m     45\u001b[0m     filter_out_non_signature_kwargs,\n\u001b[0;32m     46\u001b[0m     find_labels,\n\u001b[0;32m     47\u001b[0m     flatten_dict,\n\u001b[0;32m     48\u001b[0m     infer_framework,\n\u001b[0;32m     49\u001b[0m     is_jax_tensor,\n\u001b[0;32m     50\u001b[0m     is_numpy_array,\n\u001b[0;32m     51\u001b[0m     is_tensor,\n\u001b[0;32m     52\u001b[0m     is_tf_symbolic_tensor,\n\u001b[0;32m     53\u001b[0m     is_tf_tensor,\n\u001b[0;32m     54\u001b[0m     is_torch_device,\n\u001b[0;32m     55\u001b[0m     is_torch_dtype,\n\u001b[0;32m     56\u001b[0m     is_torch_tensor,\n\u001b[0;32m     57\u001b[0m     reshape,\n\u001b[0;32m     58\u001b[0m     squeeze,\n\u001b[0;32m     59\u001b[0m     strtobool,\n\u001b[0;32m     60\u001b[0m     tensor_size,\n\u001b[0;32m     61\u001b[0m     to_numpy,\n\u001b[0;32m     62\u001b[0m     to_py_obj,\n\u001b[0;32m     63\u001b[0m     torch_float,\n\u001b[0;32m     64\u001b[0m     torch_int,\n\u001b[0;32m     65\u001b[0m     transpose,\n\u001b[0;32m     66\u001b[0m     working_or_temp_dir,\n\u001b[0;32m     67\u001b[0m )\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     69\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[0;32m     70\u001b[0m     HF_MODULES_CACHE,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     96\u001b[0m     try_to_load_from_cache,\n\u001b[0;32m     97\u001b[0m )\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     99\u001b[0m     ACCELERATE_MIN_VERSION,\n\u001b[0;32m    100\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     torch_only_method,\n\u001b[0;32m    220\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:462\u001b[0m\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 462\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_torch_pytree\u001b[39;00m\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_model_output_flatten\u001b[39m(output: ModelOutput) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[Any], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_pytree.Context\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output\u001b[38;5;241m.\u001b[39mvalues()), \u001b[38;5;28mlist\u001b[39m(output\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:148\u001b[0m\n\u001b[0;32m    146\u001b[0m                 err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    147\u001b[0m                 err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 148\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    150\u001b[0m     kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder, lib_name):\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] Le module spécifié est introuvable. Error loading \"C:\\Users\\MAUD\\anaconda3\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#tracking mlflow\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "import mlflow.sklearn\n",
    "from time import time\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,hamming_loss, jaccard_score, confusion_matrix, roc_curve, auc)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#word2vec, BERT, USE\n",
    "#word2vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "# Bert\n",
    "import os\n",
    "import transformers\n",
    "import huggingface_hub\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel\n",
    "os.environ[\"TF_KERAS\"]='1'\n",
    "#BERT\n",
    "import torch\n",
    "#Use \n",
    "import tensorflow_hub as hub\n",
    "\n",
    "#empecher les messages d'erreur\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.disable(logging.WARNING) # disable WARNING, INFO and DEBUG logging everywhere\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Formatage taille cellule pour s'adapter aux graphiques\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.output_scroll { height: auto !important; }</style>\"))\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./filtered_questions_clean.csv\",sep=',', encoding='utf-8')  \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582047fc-127f-495d-97a3-5b58293e7f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les chaînes de caractères représentant des listes en véritables listes\n",
    "df['tags'] = df['tags'].apply(ast.literal_eval)\n",
    "\n",
    "# Binariser les tags\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_tags = mlb.fit_transform(df['tags'])\n",
    "\n",
    "# Séparer les données en jeux d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['clean_title', 'clean_body']], df_tags, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c8df8-8e5e-4402-8008-4b70adf592b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafa5201-a7b5-4a5e-b482-0fa3a148bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classes binarisées :\", mlb.classes_)\n",
    "number_of_classes = len(mlb.classes_)\n",
    "print(f\"Le nombre de classes uniques (tags) est : {number_of_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684ca8f9-0fd4-4a16-bcb1-93840134b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classes binarisées :\", mlb.classes_)\n",
    "number_of_classes = len(mlb.classes_)\n",
    "print(f\"Le nombre de classes uniques (tags) est : {number_of_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294c1630-22cf-49d7-a057-114de67d405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les classes ayant moins de 55 occurrences\n",
    "classes_under_55 = class_occurrences_df[class_occurrences_df['Occurrences'] < 55]\n",
    "\n",
    "# Afficher les classes et leur nombre d'occurrences\n",
    "print(classes_under_55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd0b52b-db54-4f93-8df6-3594cddebf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplir les valeurs manquantes dans 'clean_title' et 'clean_body'\n",
    "X_train['clean_title'] = X_train['clean_title'].fillna(\"\")\n",
    "X_train['clean_body'] = X_train['clean_body'].fillna(\"\")\n",
    "X_test['clean_title'] = X_test['clean_title'].fillna(\"\")\n",
    "X_test['clean_body'] = X_test['clean_body'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abe70b2-806a-48a6-a572-347d169d2134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_minority_classes(X_train_vect, y_train, threshold=50, n_samples=100, random_state=42):\n",
    "    \"\"\"\n",
    "    Suréchantillonne les classes minoritaires dans le jeu de données d'entraînement.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train_vect: Matrice des features d'entraînement (sparse matrix)\n",
    "        y_train: Labels d'entraînement\n",
    "        threshold: Seuil maximum de présence pour considérer une classe comme minoritaire\n",
    "        n_samples: Nombre d'échantillons après suréchantillonnage pour les classes minoritaires\n",
    "        random_state: Random state pour reproductibilité\n",
    "    \n",
    "    Returns:\n",
    "        X_train_oversampled, y_train_oversampled: Données suréchantillonnées\n",
    "    \"\"\"\n",
    "    # Convertir la matrice sparse en DataFrame pour suréchantillonnage\n",
    "    X_train_df = pd.DataFrame(X_train_vect.toarray())\n",
    "    y_train_oversampled = y_train.copy()\n",
    "    X_train_oversampled = X_train_df.copy()\n",
    "\n",
    "    for i in range(y_train.shape[1]):\n",
    "        if np.sum(y_train[:, i]) < threshold:  # Suréchantillonner les classes avec moins d'occurrences que le seuil\n",
    "            indices = np.where(y_train[:, i] == 1)[0]\n",
    "            \n",
    "            # Vérifier si indices n'est pas vide\n",
    "            if len(indices) > 0:\n",
    "                X_resampled, y_resampled = resample(X_train_df.iloc[indices], y_train[indices], \n",
    "                                                    n_samples=n_samples, random_state=random_state)\n",
    "                X_train_oversampled = pd.concat([X_train_oversampled, X_resampled])\n",
    "                y_train_oversampled = np.vstack([y_train_oversampled, y_resampled])\n",
    "\n",
    "    # Convertir en matrice sparse après suréchantillonnage\n",
    "    X_train_oversampled_sparse = np.asarray(X_train_oversampled)\n",
    "    \n",
    "    return X_train_oversampled_sparse, y_train_oversampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051bc86e-634f-4bf0-aaba-2a8e9dfd429c",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3089a3d-a392-4a69-af0e-489281cd6d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les phrases pour Word2Vec\n",
    "sentences = [text.split() for text in X_train['clean_title'] + \" \" + X_train['clean_body']]\n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Fonction pour obtenir la moyenne des embeddings Word2Vec pour un texte\n",
    "def get_w2v_features(text, model):\n",
    "    words = text.split()\n",
    "    word_vecs = [model.wv[word] for word in words if word in model.wv]\n",
    "    return np.mean(word_vecs, axis=0) if word_vecs else np.zeros(model.vector_size)\n",
    "\n",
    "# Appliquer aux jeux d'entraînement et de test\n",
    "X_train_w2v = np.array([get_w2v_features(text, word2vec_model) for text in X_train['clean_title'] + \" \" + X_train['clean_body']])\n",
    "X_test_w2v = np.array([get_w2v_features(text, word2vec_model) for text in X_test['clean_title'] + \" \" + X_test['clean_body']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d3789-c96c-45cc-8e61-eb9ca5fe7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v_oversampled, y_train_w2v_oversampled = oversample_minority_classes(X_train_w2v, y_train, min_occurrences=50, target_samples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8ef655-cffa-4a63-ac4d-74f4c7de2ce2",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce502d-bef6-4dd5-977a-bcdef586bd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le tokenizer et le modèle BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Fonction pour obtenir les embeddings BERT\n",
    "def get_bert_features(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "# Appliquer aux jeux d'entraînement et de test\n",
    "X_train_bert = np.array([get_bert_features(text, tokenizer, bert_model).flatten() for text in X_train['clean_title'] + \" \" + X_train['clean_body']])\n",
    "X_test_bert = np.array([get_bert_features(text, tokenizer, bert_model).flatten() for text in X_test['clean_title'] + \" \" + X_test['clean_body']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f43900-f9f6-4046-a9cf-d1030883f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bert_oversampled, y_train_bert_oversampled = oversample_minority_classes(X_train_bert, y_train, min_occurrences=50, target_samples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aad8966-2150-40b0-bad7-24f452e2f949",
   "metadata": {},
   "source": [
    "### USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5b78d-2730-4686-8cbf-60d97019eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle USE\n",
    "use_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "# Fonction pour obtenir les embeddings USE\n",
    "def get_use_features(text, model):\n",
    "    return model([text]).numpy().flatten()\n",
    "\n",
    "# Appliquer aux jeux d'entraînement et de test\n",
    "X_train_use = np.array([get_use_features(text, use_model) for text in X_train['clean_title'] + \" \" + X_train['clean_body']])\n",
    "X_test_use = np.array([get_use_features(text, use_model) for text in X_test['clean_title'] + \" \" + X_test['clean_body']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b27c7-2212-47ce-8b43-1ba96f5d1bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_use_oversampled, y_train_use_oversampled = oversample_minority_classes(X_train_use, y_train, min_occurrences=50, target_samples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dfe99a-3b3f-4f4b-8d59-0fe878da01ec",
   "metadata": {},
   "source": [
    "## Définir les modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9f3cad-484f-474c-834c-e914cf5007a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les modèles\n",
    "logistic_regression_model = OneVsRestClassifier(LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'))\n",
    "sgd_classifier_model = OneVsRestClassifier(SGDClassifier(max_iter=1000, random_state=42, class_weight='balanced', loss='log_loss'))\n",
    "\n",
    "# Définir les paramètres et exécuter les expériences\n",
    "# Word2Vec + Logistic Regression\n",
    "params_w2v_lr = {\n",
    "    \"model_type\": \"Logistic Regression (OneVsRest)\",\n",
    "    \"vectorizer\": \"Word2Vec\"\n",
    "}\n",
    "\n",
    "# BERT + Logistic Regression\n",
    "params_bert_lr = {\n",
    "    \"model_type\": \"Logistic Regression (OneVsRest)\",\n",
    "    \"vectorizer\": \"BERT\"\n",
    "}\n",
    "\n",
    "# USE + Logistic Regression\n",
    "params_use_lr = {\n",
    "    \"model_type\": \"Logistic Regression (OneVsRest)\",\n",
    "    \"vectorizer\": \"USE\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Word2Vec + SGDClassifier\n",
    "params_w2v_sgd = {\n",
    "    \"model_type\": \"SGDClassifier (OneVsRest)\",\n",
    "    \"vectorizer\": \"Word2Vec\"\n",
    "}\n",
    "\n",
    "# BERT + SGDClassifier\n",
    "params_bert_sgd = {\n",
    "    \"model_type\": \"SGDClassifier (OneVsRest)\",\n",
    "    \"vectorizer\": \"BERT\"\n",
    "}\n",
    "\n",
    "# USE + SGDClassifier\n",
    "params_use_sgd = {\n",
    "    \"model_type\": \"SGDClassifier (OneVsRest)\",\n",
    "    \"vectorizer\": \"USE\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b855f3c-fd49-4a77-810a-0f2bad196ce6",
   "metadata": {},
   "source": [
    "## Fonction d'execution du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2673c2e-79a5-4f0d-b63c-10412f318c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, X_train, y_train, X_test, y_test, method_name, vectorizer, reference_model=None):\n",
    "    \"\"\"\n",
    "    Exécute l'entraînement et l'évaluation du modèle.\n",
    "    \n",
    "    Parameters:\n",
    "        model: Le modèle à entraîner.\n",
    "        X_train: Les features d'entraînement.\n",
    "        y_train: Les labels d'entraînement.\n",
    "        X_test: Les features de test.\n",
    "        y_test: Les labels de test.\n",
    "        method_name: Le nom de la méthode pour l'identification.\n",
    "        vectorizer: Le vectoriseur utilisé pour calculer le taux de couverture des mots.\n",
    "        reference_model: Un modèle de référence pour comparaison (facultatif).\n",
    "\n",
    "    Returns:\n",
    "        results: Un dictionnaire contenant l'accuracy, le rapport de classification, le Jaccard score,\n",
    "                 le taux de couverture, et le modèle entraîné.\n",
    "    \"\"\"\n",
    "    # Entraîner le modèle\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Prédire les probabilités sur l'ensemble de test\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    # Initialiser une matrice vide pour les prédictions\n",
    "    y_pred = np.zeros_like(y_pred_proba, dtype=int)\n",
    "    \n",
    "    # Appliquer le seuil de 0.5 et assigner les prédictions\n",
    "    threshold = 0.5\n",
    "    for i, proba in enumerate(y_pred_proba):\n",
    "        indices_above_threshold = np.where(proba >= threshold)[0]\n",
    "        if len(indices_above_threshold) > 0:\n",
    "            y_pred[i, indices_above_threshold] = 1\n",
    "        else:\n",
    "            top_5_indices = np.argsort(proba)[-5:]\n",
    "            y_pred[i, top_5_indices] = 1\n",
    "    \n",
    "    # Calculer les métriques\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    jaccard = jaccard_score(y_test, y_pred, average='samples', zero_division=0)\n",
    "    report = classification_report(y_test, y_pred, target_names=mlb.classes_, zero_division=0)\n",
    "    word_coverage = calculate_word_coverage(X_test, vectorizer)\n",
    "    \n",
    "    # Retourner les résultats sous forme de dictionnaire\n",
    "    results = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"jaccard\": jaccard,\n",
    "        \"word_coverage\": word_coverage,\n",
    "        \"report\": report,\n",
    "        \"model\": model\n",
    "    }\n",
    "    \n",
    "    print(f\"{method_name} Classification Report:\")\n",
    "    print(report)\n",
    "    print(f\"Jaccard Score: {jaccard:.2f}\")\n",
    "    print(f\"Word Coverage: {word_coverage:.2f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8bcb1d-fc11-46f7-9904-14d18687be0e",
   "metadata": {},
   "source": [
    "## Fonction pour Cacluler le taux de couverture des mots des questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d12ebb-fd29-4136-bced-f568ce6a91bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_coverage(X_test, vectorizer):\n",
    "    \"\"\"\n",
    "    Calcule le taux de couverture des mots dans le jeu de test par rapport au vocabulaire du vectorizer.\n",
    "    \n",
    "    Parameters:\n",
    "        X_test: Jeu de test (DataFrame avec des colonnes 'clean_title' et 'clean_body')\n",
    "        vectorizer: Vectoriseur déjà entraîné sur le jeu d'entraînement\n",
    "    \n",
    "    Returns:\n",
    "        coverage_rate: Le pourcentage de mots du jeu de test couverts par le vocabulaire du vectorizer\n",
    "    \"\"\"\n",
    "    # Remplir les valeurs manquantes avec des chaînes vides\n",
    "    X_test = X_test.fillna(\"\")\n",
    "    \n",
    "    # Nombre total de mots uniques dans le vocabulaire (déjà appris lors du fit sur X_train)\n",
    "    total_vocab = len(vectorizer.get_feature_names_out())\n",
    "    \n",
    "    # Transformer les questions de test pour obtenir les mots utilisés dans X_test\n",
    "    X_test_transformed = vectorizer.transform(X_test['clean_title'] + \" \" + X_test['clean_body'])\n",
    "    \n",
    "    # Compter le nombre de mots uniques utilisés dans le jeu de test\n",
    "    word_usage = (X_test_transformed > 0).sum(axis=0)\n",
    "    covered_words = (word_usage > 0).sum()\n",
    "    \n",
    "    # Calculer le taux de couverture par rapport au vocabulaire total\n",
    "    coverage_rate = covered_words / total_vocab\n",
    "    return coverage_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c101a6-3f96-4411-9c1a-d1f1b401a965",
   "metadata": {},
   "source": [
    "## Fonction d'enregistrement des logs MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc4855e-e1eb-4d59-9013-d76684b713c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_experiment_to_mlflow(results, params, method_name, threshold=0.5, model_name=\"My_Model\"):\n",
    "    \"\"\"\n",
    "    Enregistre les résultats de l'expérimentation dans MLflow et enregistre le modèle dans le Model Registry.\n",
    "    \n",
    "    Parameters:\n",
    "        results: Un dictionnaire contenant l'accuracy, le rapport de classification, et le modèle entraîné.\n",
    "        params: Les paramètres du modèle et de la vectorisation à enregistrer dans MLflow.\n",
    "        method_name: Le nom de la méthode pour l'identification.\n",
    "        threshold: Le seuil utilisé pour déterminer les classes avec predict_proba.\n",
    "        model_name: Le nom sous lequel le modèle sera enregistré dans le Model Registry.\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=method_name) as run:\n",
    "        # Loguer les paramètres\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Loguer les métriques\n",
    "        mlflow.log_metric(\"accuracy\", results[\"accuracy\"])\n",
    "        mlflow.log_metric(\"jaccard_score\", results[\"jaccard\"])\n",
    "        mlflow.log_metric(\"word_coverage\", results[\"word_coverage\"])\n",
    "        \n",
    "        # Loguer le seuil utilisé pour les prédictions avec predict_proba\n",
    "        mlflow.log_param(\"threshold\", threshold)\n",
    "        \n",
    "        # Loguer la logique d'application du seuil et de sélection des 5 meilleures probabilités\n",
    "        mlflow.log_param(\"prediction_logic\", \"Threshold at 0.5, top 5 if none above threshold\")\n",
    "        \n",
    "        # Loguer le rapport de classification comme un fichier texte\n",
    "        mlflow.log_text(results[\"report\"], f\"classification_report_{method_name}.txt\")\n",
    "        \n",
    "        # Loguer le modèle comme un artefact MLflow\n",
    "        mlflow.sklearn.log_model(results[\"model\"], f\"{method_name}_model\")\n",
    "\n",
    "        # Enregistrement du modèle dans le registre de modèles\n",
    "        model_uri = f\"runs:/{run.info.run_id}/{method_name}_model\"\n",
    "        try:\n",
    "            registered_model = mlflow.register_model(model_uri, model_name)\n",
    "            print(f\"Le modèle '{method_name}' a été enregistré dans le Model Registry avec le nom '{model_name}'.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de l'enregistrement dans le Model Registry: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aaebd6-eefd-4495-a533-ad139073b33e",
   "metadata": {},
   "source": [
    "## Execution des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8818ad-14e4-4430-b629-2bffb6dd1f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#W2V + Logistic Regression\n",
    "results_w2v_lr = run_experiment(logistic_regression_model, X_train_w2v_oversampled, y_train_w2v_oversampled, X_test_w2v, y_test, \"w2v_logistic_regression\", vectorizer=word2vec_model)\n",
    "log_experiment_to_mlflow(results_w2v_lr, params_w2v_lr, \"w2v_logistic_regression\")\n",
    "\n",
    "#BERT + Logistic Regression\n",
    "results_bert_lr = run_experiment(logistic_regression_model, X_train_bert_oversampled, y_train_bert_oversampled, X_test_bert, y_test, \"bert_logistic_regression\", vectorizer=bert_model)\n",
    "log_experiment_to_mlflow(results_bert_lr, params_bert_lr, \"bert_logistic_regression\")\n",
    "\n",
    "#USE + Logistic Regression\n",
    "results_use_lr = run_experiment(logistic_regression_model, X_train_use_oversampled, y_train_use_oversampled, X_test_use, y_test, \"use_logistic_regression\", vectorizer=use_model)\n",
    "log_experiment_to_mlflow(results_use_lr, params_use_lr, \"use_logistic_regression\")\n",
    "\n",
    "\n",
    "\n",
    "#W2V + SGDClassifier\n",
    "results_w2v_sgd = run_experiment(sgd_classifier_model, X_train_w2v_oversampled, y_train_w2v_oversampled, X_test_w2v, y_test, \"w2v_sgd_classifier\", vectorizer=word2vec_model)\n",
    "log_experiment_to_mlflow(results_w2v_sgd, params_w2v_sgd, \"w2v_sgd_classifier\")\n",
    "\n",
    "#BERT + SGDClassifier\n",
    "results_bert_sgd = run_experiment(sgd_classifier_model, X_train_bert_oversampled, y_train_bert_oversampled, X_test_bert, y_test, \"bert_sgd_classifier\", vectorizer=bert_model)\n",
    "log_experiment_to_mlflow(results_bert_sgd, params_bert_sgd, \"bert_sgd_classifier\")\n",
    "\n",
    "#BERT + SGDClassifier\n",
    "results_use_sgd = run_experiment(sgd_classifier_model, X_train_use_oversampled, y_train_use_oversampled, X_test_use, y_test, \"use_sgd_classifier\", vectorizer=use_model)\n",
    "log_experiment_to_mlflow(results_use_sgd, params_use_sgd, \"use_sgd_classifier\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
